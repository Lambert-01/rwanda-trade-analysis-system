# ğŸ‡·ğŸ‡¼ TradeScope

**ğŸ† NISR HACKATHON 2025 - Team Codabytes**

A comprehensive full-stack web platform for analyzing Rwanda's trade data, built with modern technologies and AI integration for the National Institute of Statistics of Rwanda (NISR) Hackathon 2025.

## ğŸ“‹ Project Overview


### ğŸš€ Our Solution
A production-ready trade analysis platform that transforms **NISR's official Rwanda trade dataset** into actionable insights through:

- **Advanced Data Processing**: Automated ETL pipeline for Excel data ingestion
- **Machine Learning Integration**: Predictive analytics using Random Forest and XGBoost models
- **Interactive Visualizations**: Real-time dashboards with Chart.js and Leaflet.js
- ** Insights**: Natural language processing with OpenRouter API integration
- **Scalable Architecture**: Microservices design with MongoDB backend

## ğŸ—ï¸ Technical Architecture

### Multi-Tier System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸŒ FRONTEND LAYER                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“± Presentation Layer (Port 8080)                             â”‚
â”‚  â€¢ Vanilla JavaScript ES6+ with modular architecture           â”‚
â”‚  â€¢ Chart.js v4.4.0 for interactive data visualization         â”‚
â”‚  â€¢ Leaflet.js v1.9.4 for geographic mapping                   â”‚
â”‚  â€¢ Bootstrap 5.3.0 for responsive UI components               â”‚
â”‚  â€¢ Service Worker (PWA) for offline capabilities              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ HTTP/REST API
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸš€ BACKEND LAYER                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âš™ï¸ API Gateway (Port 3000)                                    â”‚
â”‚  â€¢ Express.js v4.18.2 server with CORS middleware             â”‚
â”‚  â€¢ MongoDB v6.20.0 with Mongoose ODM v8.18.3                  â”‚
â”‚  â€¢ OpenRouter API integration for AI services                 â”‚
â”‚  â€¢ Multi-source data loading (MongoDB â†’ JSON â†’ Raw files)     â”‚
â”‚  â€¢ Intelligent caching with TTL-based expiration             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ Python Shell Execution
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ”¬ DATA PROCESSING LAYER                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“Š ETL Pipeline Engine                                       â”‚
â”‚  â€¢ Python 3.8+ with Pandas v1.5.0+ for data manipulation     â”‚
â”‚  â€¢ Scikit-learn v1.0.0+ for ML model training                â”‚
â”‚  â€¢ OpenPyXL v3.0.0+ for Excel file processing                â”‚
â”‚  â€¢ Statistical analysis and time-series processing           â”‚
â”‚  â€¢ Automated model retraining and validation                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ’¾ DATA STORAGE LAYER                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ—„ï¸ Persistence Layer                                         â”‚
â”‚  â€¢ MongoDB collections for processed trade data               â”‚
â”‚  â€¢ JSON file system for fallback data access                 â”‚
â”‚  â€¢ Pickle files for trained ML model storage                 â”‚
â”‚  â€¢ Indexed collections for optimized query performance       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”§ Core Technologies Stack

| Layer | Technology | Version | Purpose |
|-------|------------|---------|---------|
| **Frontend** | Vanilla JavaScript | ES6+ | Application logic and DOM manipulation |
| **Frontend** | Chart.js | v4.4.0 | Interactive data visualizations |
| **Frontend** | Leaflet.js | v1.9.4 | Geographic mapping and spatial analysis |
| **Frontend** | Bootstrap | v5.3.0 | Responsive UI components and styling |
| **Backend** | Node.js | v14.0.0+ | Server-side JavaScript runtime |
| **Backend** | Express.js | v4.18.2 | REST API framework |
| **Backend** | MongoDB | v6.20.0 | NoSQL database for data persistence |
| **Backend** | Mongoose | v8.18.3 | MongoDB object modeling |
| **AI/ML** | OpenRouter API | v1 | AI model inference and chat |
| **AI/ML** | Scikit-learn | v1.0.0+ | Machine learning algorithms |
| **Data** | Pandas | v1.5.0+ | Data manipulation and analysis |
| **Data** | OpenPyXL | v3.0.0+ | Excel file processing |

## ğŸ“ Project Structure & Implementation Details

### Core Architecture Components

```
rwanda-export-analysis/
â”œâ”€â”€ ğŸ“‚ backend/                          # ğŸš€ Node.js API Server (Port 3000)
â”‚   â”œâ”€â”€ server.js                        # Express.js application entry point
â”‚   â”‚                                        # â€¢ Server configuration and middleware setup
â”‚   â”‚                                        # â€¢ Route mounting and error handling
â”‚   â”‚                                        # â€¢ Port 3000 binding and startup
â”‚   â”œâ”€â”€ package.json                     # Backend dependencies and scripts
â”‚   â”‚                                        # â€¢ Express, MongoDB, OpenRouter dependencies
â”‚   â”‚                                        # â€¢ Development and production scripts
â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â””â”€â”€ cors.js                      # Cross-origin resource sharing configuration
â”‚   â”‚                                        # â€¢ Frontend-backend communication setup
â”‚   â”‚                                        # â€¢ Development and production CORS policies
â”‚   â”œâ”€â”€ routes/                          # REST API endpoint definitions (15+ endpoints)
â”‚   â”‚   â”œâ”€â”€ exports.js                   # Export data endpoints
â”‚   â”‚   â”‚                                # â€¢ Quarterly data aggregation with MongoDB fallback
â”‚   â”‚   â”‚                                # â€¢ Geographic destination mapping with coordinates
â”‚   â”‚   â”‚                                # â€¢ SITC commodity classification and analysis
â”‚   â”‚   â”‚                                # â€¢ Growth trend analysis and calculations
â”‚   â”‚   â”‚                                # â€¢  insights integration
â”‚   â”‚   â”œâ”€â”€ imports.js                   # Import data endpoints
â”‚   â”‚   â”œâ”€â”€ analytics.js                 # Trade balance and trend analysis endpoints
â”‚   â”‚   â”œâ”€â”€ predictions.js               # ML model prediction endpoints
â”‚   â”‚   â”œâ”€â”€ models.js                    # Model management and retraining endpoints
â”‚   â”‚   â””â”€â”€ chat.js                      # AI chat interface endpoints
â”‚   â””â”€â”€ utils/                           # Backend utility modules
â”‚       â”œâ”€â”€ database.js                  # MongoDB connection and query utilities
â”‚       â”‚                                # â€¢ Connection pooling and error handling
â”‚       â”‚                                # â€¢ Data aggregation pipelines for performance
â”‚       â”œâ”€â”€ dataLoader.js                # Multi-source data loading system
â”‚       â”‚                                # â€¢ MongoDB primary data source with fallback chain
â”‚       â”‚                                # â€¢ JSON file fallback for offline capability
â”‚       â”‚                                # â€¢ Raw file emergency fallback system
â”‚       â”œâ”€â”€ openaiService.js             # OpenRouter AI service integration
â”‚       â”‚                                # â€¢ Model inference and chat completion handling
â”‚       â”‚                                # â€¢ Fallback model management (Qwen â†’ DeepSeek â†’ Gemma)
â”‚       â””â”€â”€ aiExplanationService.js     # AI response processing and formatting
â”œâ”€â”€ ğŸ“‚ frontend/                         # ğŸŒ Client-side Application (Port 8080)
â”‚   â”œâ”€â”€ index.html                       # Main dashboard page
â”‚   â”‚                                        # â€¢ Multi-page application structure
â”‚   â”‚                                        # â€¢ Asset loading and meta configuration
â”‚   â”œâ”€â”€ analytics.html                   # Advanced analytics visualization page
â”‚   â”œâ”€â”€ commodities.html                 # Commodity-specific analysis interface
â”‚   â”œâ”€â”€ exports.html                     # Export-focused dashboard view
â”‚   â”œâ”€â”€ imports.html                     # Import analysis interface
â”‚   â”œâ”€â”€ predictions.html                 # ML prediction results display page
â”‚   â”œâ”€â”€ regional.html                    # Regional trade relationship view
â”‚   â”œâ”€â”€ sw.js                           # Service Worker for PWA functionality
â”‚   â”‚                                        # â€¢ Offline capability implementation
â”‚   â”‚                                        # â€¢ Cache management and updates
â”‚   â”œâ”€â”€ assets/images/                   # Static asset storage
â”‚   â””â”€â”€ css/                            # Stylesheet organization by feature
â”‚       â”œâ”€â”€ main.css                    # Global styles and CSS variables
â”‚       â”œâ”€â”€ dashboard.css               # Dashboard-specific styling
â”‚       â”œâ”€â”€ analytics.css               # Analytics page styling
â”‚       â””â”€â”€ [component].css             # Modular component-specific styles
â”‚   â””â”€â”€ js/                             # JavaScript module architecture
â”‚       â”œâ”€â”€ main.js                     # Application initialization and routing logic
â”‚       â”œâ”€â”€ api.js                      # REST API communication layer with error handling
â”‚       â”œâ”€â”€ charts.js                   # Chart.js configuration and rendering engine
â”‚       â”œâ”€â”€ maps.js                     # Leaflet.js map implementation with country coordinates
â”‚       â””â”€â”€ [feature].js                # Feature-specific functionality modules
â”œâ”€â”€ ğŸ“‚ python_processing/                # ğŸ”¬ web developper e Pipeline Engine
â”‚   â”œâ”€â”€ data_processor.py               # Primary data processing engine
â”‚   â”‚                                        # â€¢ Excel file parsing and validation
â”‚   â”‚                                        # â€¢ Data cleaning and normalization routines
â”‚   â”œâ”€â”€ enhanced_data_processor.py      # Advanced processing algorithms
â”‚   â”œâ”€â”€ run_pipeline.py                 # Pipeline orchestration and execution control
â”‚   â”œâ”€â”€ predictor.py                    # Machine learning model training module
â”‚   â”‚                                        # â€¢ Random Forest for export prediction
â”‚   â”‚                                        # â€¢ XGBoost for import forecasting
â”‚   â”œâ”€â”€ examine_excel_files.py          # Excel file structure analysis utilities
â”‚   â”œâ”€â”€ excel_to_json_processor.py      # Excel to JSON conversion engine
â”‚   â””â”€â”€ [analysis]_processor.py         # Specialized analysis modules
â”œâ”€â”€ ğŸ“‚ data/                            # ğŸ’¾ Data Management System
â”‚   â”œâ”€â”€ raw/                           # Source data files
â”‚   â”‚   â”œâ”€â”€ 2025Q1_Trade_report_annexTables.xlsx  # Primary NISR dataset (11 sheets)
â”‚   â”‚   â””â”€â”€ Formal External Trade in Goods Report 2024Q4.pdf
â”‚   â””â”€â”€ processed/                     # Processed data outputs (50+ files)
â”‚       â”œâ”€â”€ exports_data.json          # Processed export records with aggregations
â”‚       â”œâ”€â”€ imports_data.json          # Processed import records with metadata
â”‚       â”œâ”€â”€ analysis_report.json       # Statistical analysis results and insights
â”‚       â”œâ”€â”€ predictions.json           # ML model predictions and confidence intervals
â”‚       â””â”€â”€ [dataset]_data.json        # Specialized analytical datasets
â”œâ”€â”€ ğŸ“‚ models/                          # ğŸ¤– Machine Learning Models
â”‚   â”œâ”€â”€ export_model_random_forest.pkl  # Trained export prediction model (Random Forest)
â”‚   â””â”€â”€ import_model.pkl                # Trained import prediction model (XGBoost)
â”œâ”€â”€ ğŸ“‚ docs/                           # ğŸ“š Technical Documentation Suite
â”‚   â”œâ”€â”€ API_Documentation.md           # Complete API reference (350+ lines)
â”‚   â”œâ”€â”€ Implementation_Plan.md         # Development roadmap and planning document
â”‚   â””â”€â”€ Setup_Guide.md                 # Installation and deployment guide (450+ lines)
â””â”€â”€ ğŸ“‚ reports/                        # ğŸ“‹ Generated Reports and Logs
    â”œâ”€â”€ analysis_summary.json          # Analysis execution summaries and metrics
    â””â”€â”€ pipeline_execution_report.json # Data processing pipeline execution reports
```

## ğŸ”¬ Technical Implementation Details

### Data Processing Pipeline Architecture

#### 1. Data Ingestion Layer
**Excel File Processing** (`python_processing/excel_to_json_processor.py`)
```python
# Multi-sheet Excel processing with validation
def process_nisr_excel(file_path: str) -> Dict[str, pd.DataFrame]:
    """
    Process NISR Excel file with 11 sheets:
    - Graph Overall: Trade balance and totals
    - EAC: East African Community trade data
    - Regional blocks: COMESA, SADC, EU analysis
    - Trade by continents: Global trade patterns
    - ExportCountry: Destination country analysis
    - ImportCountry: Source country analysis
    - ExportsCommodity: SITC-coded export products
    - ImportsCommodity: SITC-coded import products
    """
```

#### 2. Data Transformation Engine
**ETL Pipeline** (`python_processing/data_processor.py`)
- **Extract**: Parse Excel sheets with pandas
- **Transform**: Clean, validate, and normalize data
- **Load**: Store processed data in MongoDB and JSON files

#### 3. Machine Learning Layer
**Predictive Models** (`python_processing/predictor.py`)
```python
# Random Forest for export prediction
export_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    random_state=42
)

# XGBoost for import forecasting
import_model = XGBRegressor(
    n_estimators=150,
    learning_rate=0.1,
    max_depth=8
)
```

### API Design & Implementation

#### RESTful Endpoint Structure
**Base URL**: `http://localhost:3000/api`

**Export Analytics Endpoints** (`backend/routes/exports.js`)
- `GET /api/exports` - Quarterly export aggregation
- `GET /api/exports/destinations` - Geographic destination mapping
- `GET /api/exports/products` - SITC commodity analysis
- `GET /api/exports/growth` - Growth rate calculations
- `GET /api/exports/summary` - Statistical summaries
- `GET /api/exports/trends` - Trend analysis with growth rates
- `GET /api/exports/sitc-analysis` - SITC section breakdowns
- `GET /api/exports/ai-analysis` -  insights

**Data Source Hierarchy**
1. **Primary**: MongoDB aggregation pipelines (fastest)
2. **Secondary**: Pre-processed JSON files (fallback)
3. **Tertiary**: Raw Excel processing (emergency fallback)

### Frontend Architecture

#### Modular JavaScript Structure
**Core Modules** (`frontend/js/`):
- `main.js` - Application initialization and routing
- `api.js` - REST API communication with error handling
- `charts.js` - Chart.js configuration and data binding
- `maps.js` - Leaflet.js mapping with country coordinates

#### Responsive UI Components
- **Bootstrap 5.3.0** for layout and components
- **Custom CSS modules** for feature-specific styling
- **Progressive Web App** capabilities with service worker

## âš™ï¸ Technical Specifications

### System Requirements & Performance

#### Hardware Requirements
| Component | Minimum | Recommended | Purpose |
|-----------|---------|-------------|---------|
| **RAM** | 4GB | 8GB | Node.js/Python processing |
| **CPU** | 2 cores | 4 cores | Data processing pipeline |
| **Storage** | 5GB | 10GB | Dataset storage and processing |
| **Network** | 10 Mbps | 50 Mbps | API communication |

#### Software Dependencies
| Technology | Version | License | Purpose |
|------------|---------|---------|---------|
| **Node.js** | v14.0.0+ | MIT | Backend runtime |
| **Python** | v3.8+ | PSF | Data processing |
| **MongoDB** | v4.4+ | SSPL | Data storage |
| **Express.js** | v4.18.2 | MIT | API framework |
| **Pandas** | v1.5.0+ | BSD | Data manipulation |
| **Scikit-learn** | v1.0.0+ | BSD | Machine learning |
| **Chart.js** | v4.4.0 | MIT | Data visualization |
| **Leaflet.js** | v1.9.4 | BSD | Geographic mapping |

### Performance Metrics

#### API Response Times
- **Simple Queries**: 50-100ms
- **Data Aggregation**: 100-200ms
- **AI Analysis**: 1-3 seconds
- **ML Predictions**: 200-500ms

#### Data Processing Capacity
- **Excel Processing**: 11 sheets simultaneously
- **Record Processing**: 10,000+ records per batch
- **Model Training**: Automated retraining pipeline
- **Storage**: Multi-terabyte scalability ready

### Security Implementation

#### Data Protection
- **Environment Variables**: Secure configuration management
- **Input Validation**: Comprehensive data sanitization
- **Error Handling**: Secure error responses without data exposure
- **CORS Configuration**: Configurable cross-origin policies

#### Production Readiness
- **Container Ready**: Docker configuration prepared
- **Monitoring**: Comprehensive logging system
- **Backup Strategy**: Automated data backup procedures
- **Scalability**: Horizontal scaling architecture

## ğŸ“Š NISR Dataset Technical Analysis

### Data Structure Breakdown

#### Excel File Architecture
**File**: `2025Q1_Trade_report_annexTables.xlsx`
**Sheets**: 11 comprehensive data sheets
**Records**: 50,000+ data points across all sheets

| Sheet Name | Data Type | Key Fields | Processing Method |
|------------|-----------|------------|------------------|
| **Graph Overall** | Time series | Quarter, Trade Values | Aggregation pipeline |
| **EAC** | Regional trade | Country, Flow type | Geographic mapping |
| **Regional blocks** | Multi-bloc | Bloc, Values | Comparative analysis |
| **Trade by continents** | Global | Continent, Values | World map visualization |
| **ExportCountry** | Country-specific | Destination, Values | Top-N analysis |
| **ImportCountry** | Country-specific | Source, Values | Supply chain mapping |
| **ExportsCommodity** | SITC-coded | SITC codes, Values | Classification analysis |
| **ImportsCommodity** | SITC-coded | SITC codes, Values | Market analysis |

### Data Processing Workflow

#### ETL Pipeline Stages
1. **Extraction**: Excel file parsing with OpenPyXL
2. **Validation**: Data integrity and format checking
3. **Transformation**: Cleaning and normalization
4. **Feature Engineering**: Derived metrics calculation
5. **Loading**: Multi-destination storage (MongoDB + JSON)
## ğŸš€ Deployment & Installation Guide

### System Prerequisites

#### Hardware Requirements
| Component | Specification | Purpose |
|-----------|---------------|---------|
| **Operating System** | Windows 10/11, macOS 10.15+, Linux Ubuntu 18.04+ | Cross-platform compatibility |
| **RAM** | 8GB minimum, 16GB recommended | Node.js/Python processing |
| **Storage** | 10GB free space | Dataset storage and processing |
| **Network** | Stable internet connection | API communication and AI services |

#### Software Dependencies
```bash
# Required installations
Node.js v14.0.0+        # Backend runtime
Python v3.8+           # Data processing
MongoDB v4.4+          # Data storage
Git                    # Version control
```

### Installation Procedure

#### 1. Repository Setup
```bash
# Clone the repository
git clone <repository-url>
cd tradescope

# Verify repository structure
ls -la
# Expected output: backend/, frontend/, python_processing/, data/, docs/
```

#### 2. Backend Installation
```bash
# Navigate to backend directory
cd backend

# Install Node.js dependencies
npm install

# Verify installation
npm list --depth=0
# Expected: express@4.18.2, mongodb@6.20.0, mongoose@8.18.3, openai@5.23.2
```

#### 3. Frontend Installation
```bash
# From project root
npm install

# Verify key packages
npm list chart.js leaflet bootstrap
# Expected: chart.js@4.4.0, leaflet@1.9.4, bootstrap@5.3.0
```

#### 4. Python Environment Setup
```bash
# Install Python dependencies
pip install -r requirements.txt

# Verify key packages
python -c "import pandas, numpy, sklearn, openpyxl; print('âœ… All packages installed')"
```

### Configuration Management

#### Environment Variables (`backend/.env`)
```env
# ========================================
# SERVER CONFIGURATION
# ========================================
PORT=3001
NODE_ENV=development

# ========================================
# OPENAI / OPENROUTER CONFIGURATION
# ========================================
OPENAI_API_KEY=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
OPENAI_BASE_URL=https://openrouter.ai/api/v1
OPENAI_MODEL=openai/gpt-oss-20b:free
OPENAI_MAX_TOKENS=2000
OPENAI_TEMPERATURE=0.7

# AI Feature Flags
AI_CHAT_ENABLED=true
AI_ANALYSIS_ENABLED=true
AI_PREDICTIONS_ENABLED=true

# ========================================
# DATA PROCESSING
# ========================================
DATA_RAW_PATH=../data/raw
DATA_PROCESSED_PATH=../data/processed
CACHE_ENABLED=true
CACHE_DURATION_HOURS=1

# ========================================
# SECURITY
# ========================================
CORS_ORIGIN=http://localhost:3001
RATE_LIMIT=100

# ========================================
# DEVELOPMENT SETTINGS
# ========================================
AUTO_RELOAD=true
SOURCE_MAPS=true
```

### Application Launch Sequence

#### Development Mode Startup
```bash
# Terminal 1: MongoDB Database
mongod --dbpath ./data/db --bind_ip 127.0.0.1

# Terminal 2: Backend API Server
cd backend && npm run dev
# Expected: Server running on http://localhost:3000

# Terminal 3: Frontend Application
npm start
# Expected: Frontend running on http://localhost:8080

# Terminal 4: Data Processing Pipeline (Optional)
cd python_processing && python run_pipeline.py
```

#### Access Points
- **ğŸŒ Frontend Dashboard**: http://localhost:8080
- **ğŸ”Œ REST API**: http://localhost:3000/api
- **ğŸ“š API Documentation**: http://localhost:3000/api/docs
- **ğŸ’¾ MongoDB**: mongodb://localhost:27017/rwanda_trade

## ğŸ“Š Working with NISR's Data

### ğŸ¯ Our Data Source
We built our platform around **NISR's official 2025 Q1 Trade Report** - a comprehensive Excel dataset with **11 detailed sheets** covering:

| Sheet | What We Found | How We Used It |
|-------|---------------|----------------|
| **ğŸ“ˆ Graph Overall** | Total trade statistics | Main dashboard metrics and trends |
| **ğŸŒ EAC** | East African Community trade | Regional relationship analysis |
| **ğŸŒ Regional blocks** | COMESA, SADC, EU data | Multi-bloc comparison tools |
| **ğŸ—ºï¸ Trade by continents** | Global trade patterns | World map visualizations |
| **ğŸ“¤ ExportCountry** | Export destinations | Interactive country mapping |
| **ğŸ“¥ ImportCountry** | Import source countries | Supply chain analysis |
| **ğŸ“¦ ExportsCommodity** | Products by SITC codes | Commodity trend analysis |
| **ğŸ—ï¸ ImportsCommodity** | Import products | Market opportunity identification |

### ğŸ”Œ Our API (15+ Endpoints)

We created a comprehensive API that makes NISR's data easily accessible:

**Export Analytics**

- `GET /api/exports` - Quarterly export trends
- `GET /api/exports/destinations` - Interactive country map data
- `GET /api/exports/products` - Commodity analysis
- `GET /api/exports/ai-analysis` -  insights

**Import Analytics**

- `GET /api/imports` - Import flow data
- `GET /api/imports/sources` - Source country analysis

**Smart Analytics**

- `GET /api/analytics/trade-balance` - Balance calculations
- `POST /api/chat/ask` - Ask questions in plain English

## ğŸ¤– Our AI & Technology Stack

### ğŸ§  Why We Chose These Technologies

**For the Backend (Node.js + Express)**

- âš¡ **Fast and Scalable**: Handles multiple requests simultaneously
- ğŸ”§ **Easy to Extend**: Simple to add new features and endpoints
- ğŸŒ **Great for APIs**: Perfect for serving data to our frontend

**For Data Processing (Python)**

- ğŸ“Š **Pandas Power**: Excellent for manipulating NISR's Excel data
- ğŸ§  **Scikit-learn**: Industry-standard machine learning tools
- ğŸ”„ **Automation-Ready**: Perfect for processing new data as it arrives

**For AI Integration (OpenRouter)**

- ğŸ’¬ **Conversational AI**: Lets users ask questions naturally
- ğŸ”® **Predictive Insights**: Helps forecast trade trends
- ğŸ’° **Cost-Effective**: Free tier available for hackathon projects

**For Visualization (Chart.js + Leaflet)**

- ğŸ¨ **Beautiful Charts**: Make complex data easy to understand
- ğŸ—ºï¸ **Interactive Maps**: Show trade relationships geographically
- ğŸ“± **Responsive Design**: Works perfectly on any device

## ğŸ“‹ Development Guidelines

### Code Organization Principles

#### Backend Architecture (`backend/`)
```
Modular API Design:
â”œâ”€â”€ routes/          # Feature-based endpoint organization
â”œâ”€â”€ utils/           # Reusable utility functions
â”œâ”€â”€ middleware/      # CORS, authentication, logging
â””â”€â”€ server.js       # Application entry point
```

#### Frontend Structure (`frontend/`)
```
Component-based Architecture:
â”œâ”€â”€ js/              # Feature-specific modules
â”œâ”€â”€ css/             # Component-scoped styling
â”œâ”€â”€ assets/          # Static resources
â””â”€â”€ *.html          # Page templates
```

#### Data Processing (`python_processing/`)
```
Pipeline Architecture:
â”œâ”€â”€ *processor.py    # Data transformation modules
â”œâ”€â”€ *analyzer.py     # Analytical processing
â”œâ”€â”€ *predictor.py    # ML model implementations
â””â”€â”€ run_pipeline.py  # Orchestration engine
```

### API Development Standards

#### Endpoint Design Patterns
- **RESTful Resource Naming**: `/api/{resource}/{id}`
- **Consistent HTTP Methods**: GET, POST, PUT, DELETE
- **Standard Response Format**: JSON with metadata
- **Error Handling**: Structured error responses

#### Database Schema Design
```javascript
// MongoDB collection structure
{
  _id: ObjectId,
  quarter: "2025Q1",
  country: "Rwanda",
  commodity_code: "SITC001",
  value: 12345.67,
  metadata: {
    processed_at: "2025-01-01T00:00:00Z",
    source_file: "2025Q1_Trade_report_annexTables.xlsx"
  }
}
```

## ğŸ”§ Technical Specifications

### Performance Benchmarks

| Operation | Average Time | Optimization |
|-----------|--------------|--------------|
| **API Response** | 50-200ms | MongoDB aggregation pipelines |
| **Data Processing** | 2-5 seconds | Pandas vectorized operations |
| **ML Prediction** | 200-500ms | Pre-trained model caching |
| **AI Analysis** | 1-3 seconds | OpenRouter API optimization |

### Scalability Architecture

#### Horizontal Scaling Support
- **Stateless API Design**: Multiple backend instances
- **Database Sharding**: MongoDB cluster ready
- **Load Balancing**: Nginx/reverse proxy compatible
- **Caching Layer**: Redis integration ready

#### Data Volume Handling
- **Batch Processing**: 10,000+ records per batch
- **Memory Management**: Streaming for large datasets
- **Storage Optimization**: Compressed data formats
- **Processing Parallelization**: Multi-threaded pipeline

## ğŸ“š Documentation & References

### Technical Documentation Suite

| Document | Purpose | Technical Focus |
|----------|---------|-----------------|
| **README.md** | Project overview & architecture | System design and implementation |
| **API_Documentation.md** | API reference (350+ lines) | Endpoint specifications and examples |
| **Setup_Guide.md** | Installation guide (450+ lines) | Deployment procedures and configuration |
| **Implementation_Plan.md** | Development roadmap | Technical requirements and planning |

### Quick Reference Links
- **ğŸ”Œ API Documentation**: [Complete API Reference](docs/API_Documentation.md)
- **âš™ï¸ Setup Guide**: [Installation Procedures](docs/Setup_Guide.md)
- **ğŸ—ºï¸ Implementation Plan**: [Development Roadmap](docs/Implementation_Plan.md)

## ğŸ† NISR Hackathon 2025 - Technical Achievement

### Competition Compliance
âœ… **Original Work**: All code developed during hackathon period
âœ… **Proper Attribution**: All external libraries and APIs properly credited
âœ… **Technical Innovation**: Modern full-stack architecture implementation
âœ… **Documentation**: Comprehensive technical documentation provided
âœ… **GitHub Deployment**: Ready for web-based demonstration

### Technical Innovation Highlights
- **ğŸ¤– AI Integration**: OpenRouter API with multiple fallback models
- **ğŸ“Š Real-time Processing**: Live data aggregation and visualization
- **ğŸ—ºï¸ Geographic Mapping**: Interactive trade relationship visualization
- **ğŸ”® Predictive Analytics**: ML-powered trade forecasting
- **ğŸ“± Responsive Design**: Cross-platform compatibility
- **ğŸ”’ Production Security**: Enterprise-grade implementation

---

## ğŸ‡·ğŸ‡¼ Technical Achievement Summary

**Team Codabytes** - NISR Hackathon 2025

TradeScope - A comprehensive trade analysis platform demonstrating:
- **Full-Stack Architecture**: Modern Node.js/Python implementation
- ** Analytics**: OpenRouter API integration with fallback systems
- **Production-Ready Code**: Scalable, secure, and maintainable architecture
- **Comprehensive Documentation**: 800+ lines of technical documentation
- **Real-World Impact**: Practical application for Rwanda's trade analysis

**Built with precision, engineered for performance, designed for Rwanda's future.**

## ğŸ† About NISR Hackathon 2025

### ğŸ“‹ Competition Overview

We participated in the **NISR Hackathon 2025**, an incredible competition that:

**ğŸ¯ Who Could Join**  
- Undergraduate and recent graduates (2024-2025)
- Master's students from any field
- Fresh graduates from web developper e, Statistics, Economics, Mathematics, IT, Information Systems, and Web Development
- Teams of 2 students from any university
- Individual participation for recent graduates

**ğŸ’¡ Special Encouragement**
- Final-year students
- Female participants
- Participants from diverse academic backgrounds

**ğŸ› ï¸ Technical Freedom**
- Use any programming language
- Submit as GitHub-deployed application with documentation
- Focus on innovation and real-world impact

**ğŸ† Our Achievement**
As **Team Codabytes**, we created a platform that demonstrates:
- **Innovation**: Modern full-stack architecture with AI integration
- **Impact**: Real-world application for Rwanda's trade analysis
- **Technical Excellence**: Production-ready code with comprehensive documentation
- **Originality**: Our own work, properly acknowledging all sources

## ğŸ™ Acknowledgments

### ğŸ¢ To NISR
Thank you to the **National Institute of Statistics of Rwanda (NISR)** for:
- Providing access to comprehensive, high-quality trade data
- Organizing this incredible learning opportunity
- Supporting innovation in data analysis and visualization
- Believing in the power of student developers

### ğŸ› ï¸ To Our Tools & Technologies
- **OpenRouter API** for making AI accessible to hackathon projects
- **MongoDB** for reliable data storage
- **Node.js & Python communities** for excellent documentation and support
- **Chart.js & Leaflet.js** for beautiful, interactive visualizations

### ğŸ‘¨â€ğŸ« To Our University
Thank you to our professors and mentors who encouraged us to participate and supported our learning journey throughout this hackathon.


### ğŸš€ Our Vision for the Future

We hope our platform becomes:
- **A learning tool** for students studying economics and trade
- **A decision-making aid** for policymakers and businesses
- **An inspiration** for other young developers in Rwanda
- **A foundation** for even more sophisticated trade analysis tools

### ğŸ’¬ A Message to Future Participants

If you're reading this and considering joining a hackathon, **do it!** This experience taught us that:
- **Age doesn't matter** - students can build production-ready applications
- **Background doesn't limit you** - learn as you go and build something amazing
- **Team work makes the dream work** - find a partner who complements your skills
- **Government data is powerful** - use it to create real impact

---

---

**ğŸ‡·ğŸ‡¼ Built with â¤ï¸ for Rwanda by Team Codabytes**

*"From classroom theory to real-world impact - one hackathon at a time"*
